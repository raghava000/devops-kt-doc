<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DevOps Knowledge Transfer: Weeks 1-3</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
            background-color: #f8f9fa;
            color: #212529;
            margin: 0;
            padding: 2em;
            line-height: 1.6;
        }
        .container { max-width: 1000px; margin: 0 auto; }
        .main-title { text-align: center; color: #2c3e50; margin-bottom: 2em; }
        .week-section { margin-bottom: 2.5em; }
        .week-title {
            font-size: 2em;
            color: #fff;
            padding: 0.5em 1em;
            border-radius: 8px;
            margin-bottom: 1em;
        }
        .week-1-title { background-color: #3498db; }
        .week-2-title { background-color: #e74c3c; }
        .week-3-title { background-color: #9b59b6; }
        details {
            background: #fff;
            border-radius: 8px;
            margin-bottom: 1em;
            box-shadow: 0 2px 8px rgba(0,0,0,0.07);
            border-left: 5px solid #bdc3c7;
            transition: all 0.3s ease;
        }
        details[open] { border-left-color: inherit; }
        .week-1 details[open] { border-left-color: #3498db; }
        .week-2 details[open] { border-left-color: #e74c3c; }
        .week-3 details[open] { border-left-color: #9b59b6; }
        summary {
            padding: 1em 1.5em;
            cursor: pointer;
            font-size: 1.2em;
            font-weight: 600;
            color: #34495e;
            list-style: none;
            outline: none;
        }
        summary::-webkit-details-marker { display: none; }
        summary::before {
            content: 'â–º';
            margin-right: 0.8em;
            font-size: 0.8em;
            transition: transform 0.2s;
            display: inline-block;
        }
        details[open] > summary::before { transform: rotate(90deg); }
        .day-content { padding: 0 1.5em 1.5em 1.5em; border-top: 1px solid #ecf0f1; }
        h4 {
            font-size: 1.1em;
            color: #2980b9;
            border-bottom: 2px solid #ecf0f1;
            padding-bottom: 0.3em;
            margin-top: 1.5em;
        }
        .week-2 h4 { color: #c0392b; }
        .week-3 h4 { color: #8e44ad; }
        p { color: #555; }
        code {
            background-color: #ecf0f1;
            padding: 0.2em 0.4em;
            border-radius: 4px;
            font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, Courier, monospace;
            font-size: 0.9em;
        }
        pre {
            background-color: #2c3e50;
            color: #ecf0f1;
            padding: 1em;
            border-radius: 6px;
            overflow-x: auto;
            white-space: pre-wrap;
            font-size: 0.9em;
        }
        pre code { background: none; padding: 0; }
        .challenge-section {
            background-color: #fff9e6;
            border-left: 4px solid #f1c40f;
            padding: 1em;
            margin: 1.5em 0;
        }
        .challenge-section.red {
             background-color: #fff5f5;
             border-left-color: #c0392b;
        }
        .challenge-section strong { color: #d35400; }
        .challenge-section.red strong { color: #c0392b; }
    </style>
</head>
<body>
    <div class="container">
        <h1 class="main-title">DevOps Knowledge Transfer (Weeks 1-3)</h1>

        <!-- WEEK 1 SECTION -->
        <section class="week-section">
            <h2 class="week-title week-1-title">Week 1: Container Orchestration with Docker & Kubernetes</h2>
            <details>
                <summary>Day 1-2: Code to Container to Cloud Registry</summary>
                <div class="day-content">
                    <h4>Goal:</h4>
                    <p>Package a Python app into a portable Docker Image and push it to a private Artifact Registry.</p>
                    <h4>The "How" (Commands & Files):</h4>
<pre><code># Dockerfile - The application blueprint
# Start FROM a known base image. 'python:3.9-slim' is a lightweight official image.
FROM python:3.9-slim
# Set the WORKing DIRectory inside the container to '/app'. All subsequent commands run here.
WORKDIR /app
# COPY the requirements file first to leverage Docker's layer caching.
COPY requirements.txt .
# RUN the command to install the Python libraries inside the container.
RUN pip install -r requirements.txt
# COPY the rest of the application code into the '/app' directory.
COPY . .
# Set the default CoMmanD to execute when the container starts.
CMD ["python", "app.py"]

# .dockerignore - A list of files to exclude from the build context.
# This makes builds faster and more secure.
__pycache__/
*.pyc

# Build the image from the Dockerfile in the current directory ('.')
# and give it a local tag (name) of 'my-app'.
docker build -t my-app .

# Run the container, mapping the host machine's port 5001 to the container's internal port 5000.
docker run -p 5001:5000 my-app

# Tag the local 'my-app' image with its full, official remote address for the registry.
docker tag my-app asia-south1-docker.pkg.dev/PROJECT_ID/REPO_NAME/my-app:v1.0.0

# Push the officially tagged image to the remote registry.
docker push asia-south1-docker.pkg.dev/PROJECT_ID/REPO_NAME/my-app:v1.0.0
</code></pre>
                </div>
            </details>
            <details>
                <summary>Day 3-7: Deploying a Complete Application on GKE</summary>
                <div class="day-content">
                    <h4>Goal:</h4>
                    <p>Deploy a multi-replica, self-healing, auto-scaling, and updatable application on a managed GKE cluster.</p>
                    <h4>The "How" (Commands & Files):</h4>
<pre><code># --- deployment.yaml ---
# The version of the Kubernetes API to use for this object.
apiVersion: apps/v1
# The type of object we want to create. A Deployment manages a set of replica Pods.
kind: Deployment
# Metadata about this Deployment object itself.
metadata:
  name: my-web-app
# The specification, or "desired state," of the Deployment.
spec:
  # Always maintain this many identical Pods.
  replicas: 3
  # The rule the Deployment uses to find the Pods it is responsible for.
  selector:
    # It will look for any Pod with a label that matches this.
    matchLabels:
      app: web
  # The template (blueprint) for a single Pod. The Deployment will create its replicas based on this.
  template:
    # The metadata for the Pod, including its labels.
    metadata:
      # This label MUST match the Deployment's selector above. This is the link.
      labels:
        app: web
    # The specification for what goes inside the Pod.
    spec:
      # A list of containers to run inside this Pod.
      containers:
      # The first (and only) container.
      - name: nginx
        # The Docker image to use for this container.
        image: nginx:1.14.2
        # A list of network ports this container exposes.
        ports:
        - containerPort: 80
        # CRITICAL for Autopilot: Resource requests must be set for scheduling and autoscaling.
        resources:
          requests:
            memory: "64Mi" # Request 64 Megabytes of RAM.
            cpu: "250m"   # Request 25% of one CPU core.

# --- service.yaml ---
apiVersion: v1
kind: Service
metadata:
  name: my-web-service
spec:
  # A ClusterIP service is only accessible from INSIDE the cluster. It's an internal "street sign."
  type: ClusterIP
  # The rule the Service uses to find the Pods it should send traffic to.
  selector:
    # This must match the labels on the Pods you want to target.
    app: web
  # Defines how traffic is routed.
  ports:
  # The first (and only) port rule.
  - protocol: TCP
    # The port of the Service itself (the port on the "street sign").
    port: 80
    # The port on the Pods that the traffic should be forwarded to.
    targetPort: 80
</code></pre>
                </div>
            </details>
            <div class="challenge-section red">
                <h4>Week 1 Biggest Challenge: "The Cloud Fortress"</h4>
                <p><strong>The Problem:</strong> My container worked locally but was unreachable on a cloud VM, resulting in a cascade of errors: <code>Connection Refused</code>, <code>Permission Denied</code>, <code>Unauthorized</code>.</p>
                <p><strong>The Debugging Process:</strong> I learned that a cloud environment is secure by default. I had to solve problems at three distinct layers: Networking, Firewall, and IAM. I learned to use a VM's <strong>External IP</strong>, create a <strong>firewall rule</strong> (<code>gcloud compute firewall-rules create</code>), and grant the VM's Service Account the correct <strong>IAM Role</strong> (<code>gcloud projects add-iam-policy-binding</code>).</p>
            </div>
        </section>

        <!-- WEEK 2 SECTION -->
        <section class="week-section">
            <h2 class="week-title week-2-title">Week 2: Configuration Management with Ansible</h2>
             <details>
                <summary>Day 8-14: Automating a Multi-Tier Application</summary>
                <div class="day-content">
                    <h4>Goal:</h4>
                    <p>Use Ansible to automate the setup of a two-tier application (web + database), organize the code into Roles, and secure secrets with Vault.</p>
                    <h4>The "How" (Commands & Files):</h4>
<pre><code># --- inventory.ini ---
# This file is Ansible's "address book."
[webservers]
# The nickname, the real IP address, the user to connect as, and the SSH key to use.
node1 ansible_host=IP_ADDRESS ansible_user=USERNAME ansible_ssh_private_key_file=~/.ssh/google_compute_engine

# --- ansible.cfg ---
# This file sets default behaviors for Ansible.
[defaults]
# Automatically use this inventory file.
inventory = inventory.ini
# Automatically bypass the first-time SSH host key prompt (essential for automation).
host_key_checking = false

# --- site.yaml (The Master Plan) ---
# This top-level playbook connects hosts to their roles.
---
- name: Configure Web Server
  # The WHERE: Run this on all hosts in the 'webservers' group from the inventory.
  hosts: webservers
  # The HOW: Run all tasks with sudo.
  become: yes
  # The WHAT: Execute the tasks defined in the 'web' role.
  roles:
    - web

# --- roles/db/vars/main.yaml (Encrypted Vault File) ---
# This file stores sensitive data. It is created with 'ansible-vault create'.
# It contains a simple key-value pair.
mysql_root_password: "my-super-secret-pw-123"

# --- roles/db/tasks/main.yaml (A Role's Task List) ---
# A self-contained list of tasks to configure the database server.
# It starts directly with the first task (no 'tasks:' keyword).
- name: Install required system packages for Docker
  apt:
    name:
      - python3-docker
      - docker-ce
    state: present
    update_cache: yes
# ... other tasks to install Docker ...
- name: Run the MySQL container
  docker_container:
    name: mysql-db
    image: mysql:5.7
    state: started
    # The 'env' block sets environment variables inside the container.
    env:
      # Use the variable from the encrypted vault file. The '{{...}}' syntax is for variables.
      MYSQL_ROOT_PASSWORD: "{{ mysql_root_password }}"
    ports:
      - "3306:3306"
</code></pre>
                </div>
            </details>
            <div class="challenge-section red">
                <h4>Week 2 Biggest Challenge: "The Order of Operations"</h4>
                <p><strong>The Problem:</strong> My Ansible playbooks kept failing with subtle errors like <code>Group docker does not exist</code> or <code>package not found</code>.</p>
                <p><strong>The Debugging Process:</strong> I learned that automation scripts must be perfectly ordered and self-contained. The `docker` group is only created *after* the Docker package is installed, so the task to add a user must come after the installation task. Similarly, a role must contain all steps to configure its service from a blank server, including adding custom package repositories.</p>
            </div>
        </section>

        <!-- WEEK 3 SECTION -->
        <section class="week-section">
            <h2 class="week-title week-3-title">Week 3: CI/CD Pipelines with Jenkins & GitHub Actions</h2>
            <details>
                <summary>Day 15-21: Building an End-to-End Pipeline</summary>
                <div class="day-content">
                    <h4>Goal:</h4>
                    <p>Build a full CI/CD pipeline that automatically builds, tests, pushes, and deploys an application to GKE, complete with environment separation and automated rollbacks.</p>
                    <h4>The "How" (Commands & Files):</h4>
<pre><code># --- Jenkinsfile (Final, Robust Version) ---
# Defines the entire pipeline as code.
pipeline {
    # Run this on any available Jenkins agent.
    agent any
    # Define global variables for the pipeline.
    environment {
        PROJECT_ID        = 'YOUR_PROJECT_ID'
        GKE_CLUSTER       = 'your-cluster-name' 
        // ... etc.
    }
    # Define the sequential stages of the pipeline.
    stages {
        stage('Build and Push Image') {
            steps {
                # A secure block that loads a credential into a variable.
                withCredentials([string(credentialsId: 'gcp-key-id', variable: 'GCP_KEY_TEXT')]) {
                    # Use the robust 'writeFile' to create a temporary key file, avoiding shell corruption.
                    writeFile(file: '/tmp/gcp-key.json', text: GCP_KEY_TEXT)
                    # Use the key file to authenticate gcloud.
                    sh "gcloud auth activate-service-account --key-file=/tmp/gcp-key.json"
                    # Configure Docker to use gcloud's authentication.
                    sh "gcloud auth configure-docker ..."
                    # Build and push the image.
                    sh "docker build ..."
                    sh "docker push ..."
                    # Securely clean up the temporary secret file.
                    sh "rm /tmp/gcp-key.json"
                }
            }
        }
        stage('Deploy and Verify') {
            steps {
                # A 'script' block is required for advanced logic like 'try...catch'.
                script {
                    // Logic to set TARGET_NAMESPACE based on the built-in 'env.BRANCH_NAME' variable.
                    if (env.BRANCH_NAME == 'main') { TARGET_NAMESPACE = 'prod' } else { TARGET_NAMESPACE = 'dev' }
                    
                    # A safety net to handle failures.
                    try {
                        // 1. Deploy the new version.
                        sh "kubectl set image deployment/my-web-app nginx=..."
                        // 2. Verify the new version is healthy. This command will fail if the rollout gets stuck.
                        sh "kubectl rollout status deployment/my-web-app"
                    } catch (any) {
                        // 3. If verification fails, automatically roll back to the last known-good version.
                        sh "kubectl rollout undo deployment/my-web-app"
                        // 4. Fail the entire pipeline build.
                        error "Deployment failed and was rolled back."
                    }
                }
            }
        }
    }
}
</code></pre>
                </div>
            </details>
            <div class="challenge-section red">
                <h4>Week 3 Biggest Challenge: "The Broken Factory" (Jenkins)</h4>
                <p><strong>The Problem:</strong> I was plagued by a relentless series of cryptic Jenkins errors (`NoSuchMethodError`, stuck plugins, `Invalid control character`) even after rebuilding the server and correctly following instructions.</p>
                <p><strong>The Debugging Process:</strong> The key lesson was that sometimes the tool itself is the problem. After proving the plugins were fundamentally broken in my environment, the professional fix was to abandon the "magic" `withGoogleServiceAccount` step and fall back to a more robust, fundamental pattern: using a basic `Secret text` credential, writing it to a temporary file with the reliable `writeFile` step, and using that file to explicitly authenticate `gcloud`.</p>
            </div>
             <div class="challenge-section">
                <h4>Week 3 Bonus Challenge: "The Broken Connection" (Git & GitHub)</h4>
                <p><strong>The Problem:</strong> My <code>git push</code> commands were failing with <code>Authentication failed</code> because password authentication is deprecated.</p>
                <p><strong>The Debugging Process:</strong> The professional solution was to switch to SSH authentication. This involved three steps:</p>
                <ol>
                    <li><strong>Generate an SSH key pair locally:</strong> <code>ssh-keygen -t ed25519 -C "email"</code></li>
                    <li><strong>Upload the public key to GitHub:</strong> Copy the output of <code>cat ~/.ssh/id_ed25519.pub</code> and paste it into the GitHub UI.</li>
                    <li><strong>Update the local repository's remote URL:</strong> Use <code>git remote set-url origin git@github.com:USERNAME/REPO.git</code> to switch from HTTPS to the secure SSH protocol.</li>
                </ol>
            </div>
        </section>
    </div>
</body>
</html>

